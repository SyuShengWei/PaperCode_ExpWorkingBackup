{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read Data Base\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "uri = \"mongodb://localhost:27017/database\" #mongodb://<user_name>:<user_password>@ds<xxxxxx>.mlab.com:<xxxxx>/<database_name>\n",
    "conn = MongoClient(uri)\n",
    "db = conn.PaperData\n",
    "#Spectrogram_Collection  =  db.get_collection('AudioSpectrogram_100thTag')\n",
    "LineCNN_Collection  =  db.get_collection('LineCNNMatrix_100thTag_80p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lyric_Para\n",
    "_num_Lines = 80\n",
    "_num_LineLen = 25\n",
    "_num_WEDim = 100\n",
    "_num_LyricCNN_kernalSize = 3 # #CNN Size start from 3\n",
    "_num_LyricCNN_kernalnum = 100 # for each size of kernal, how many different kernals \n",
    "##3 4 5 kernal size , 100 for each is from Convolutional Neural Network for Sententce Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag para\n",
    "_num_Tags = 50\n",
    "_num_neural_TagFC1 = 512\n",
    "_num_neural_TagFC2 = 256\n",
    "_num_neural_TagFC3 = 2 #for soft max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_num_Tags = 50\n",
    "_epchos = 200\n",
    "_stopEpcho = 20\n",
    "_batchSize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import codecs\n",
    "import numpy as np\n",
    "def read_json(filename):\n",
    "    with codecs.open(filename,'r',encoding = 'utf8') as infile:\n",
    "        return np.array(json.load(infile))\n",
    "    \n",
    "x_train = read_json('x_train_'+str(_num_Tags)+'d_80p_sub.json')\n",
    "x_test = read_json('x_test_'+str(_num_Tags)+'d_80p_sub.json')\n",
    "y_train = read_json('y_train_'+str(_num_Tags)+'d_80p_sub.json')\n",
    "y_test = read_json('y_test_'+str(_num_Tags)+'d_80p_sub.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20540"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Submodel for CRNN \n",
    "\n",
    "##Here is the sub model for timeDistribute layer in main model\n",
    "\n",
    "# the share layer for all time distribution CNN\n",
    "Lines_Input = Input(name= 'TextInput',batch_shape=(None,_num_LineLen, _num_WEDim, 1)) #(None,25,100,1)\n",
    "LineFeature_List = []\n",
    "for i in range(_num_LyricCNN_kernalSize):\n",
    "    #result_shape = (timestep, sentencelen(num of CNN result for each kernal), WE_dim, num_kernal) = (None,25,100,32)\n",
    "    CL  = Conv2D(_num_LyricCNN_kernalnum, kernel_size = (i+3,_num_WEDim), padding='same')(Lines_Input) \n",
    "    AL = Activation('relu')(CL)\n",
    "    BN = BatchNormalization()(AL)\n",
    "    #max pooling for every kernal, result_shape = (None, 1, 1, 32)\n",
    "    MPL = MaxPooling2D(_num_LineLen,_num_WEDim)(BN)\n",
    "    MP_shape =  tf.shape(MPL)\n",
    "    #flatten for matching GRU input size\n",
    "    FL  = Flatten()(MPL) #result = (timestep size , )\n",
    "    LineFeature_List.append(FL)\n",
    "    \n",
    "LineFeature = concatenate(LineFeature_List)\n",
    "TextCNNMode = Model(inputs = Lines_Input, outputs = LineFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TextInput (InputLayer)          (None, 25, 100, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 25, 100, 100) 30100       TextInput[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 25, 100, 100) 40100       TextInput[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 25, 100, 100) 50100       TextInput[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 25, 100, 100) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 100, 100) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 100, 100) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 25, 100, 100) 400         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 25, 100, 100) 400         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 25, 100, 100) 400         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100)          0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 100)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 300)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 121,500\n",
      "Trainable params: 120,900\n",
      "Non-trainable params: 600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TextCNNMode.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Main model \n",
    "#Lyric feature extraction, CRNN part\n",
    "Text_Input = Input(name='LyricInput', shape=(_num_Lines,_num_LineLen, _num_WEDim, 1)) #(batch_size, timestep, 25, 100 ,1)\n",
    "TD_CNN = TimeDistributed(TextCNNMode)(Text_Input)\n",
    "GRU_F = GRU(_num_LyricCNN_kernalSize*_num_LyricCNN_kernalnum, return_sequences=False, kernel_initializer='he_normal', name='GRU_forward')(TD_CNN)\n",
    "GRU_B = GRU(_num_LyricCNN_kernalSize*_num_LyricCNN_kernalnum, return_sequences=False, kernel_initializer='he_normal', name='GRU_backward', go_backwards=True)(TD_CNN)\n",
    "LF = concatenate([GRU_F, GRU_B])\n",
    "\n",
    "#pseudo-model for sheck summary\n",
    "Softmax = Dense(_num_Tags, kernel_initializer='he_normal',activation='sigmoid')(LF)\n",
    "Main_model = Model(inputs=Text_Input, outputs=Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "LyricInput (InputLayer)                (None, 80, 25, 100, 1)     0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistributed)   (None, 80, 300)            121500        LyricInput[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "GRU_forward (GRU)                      (None, 300)                540900        time_distributed_1[0][0]                \n",
      "________________________________________________________________________________________________________________________\n",
      "GRU_backward (GRU)                     (None, 300)                540900        time_distributed_1[0][0]                \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)            (None, 600)                0             GRU_forward[0][0]                       \n",
      "                                                                                GRU_backward[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                        (None, 50)                 30050         concatenate_2[0][0]                     \n",
      "========================================================================================================================\n",
      "Total params: 1,233,350\n",
      "Trainable params: 1,232,750\n",
      "Non-trainable params: 600\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Main_model.summary(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "import json\n",
    "import codecs\n",
    "class LyricDataGenerator(Sequence):\n",
    "    #batch size can only be 1\n",
    "    def __init__(self, text_filenames, labels,batch_size):\n",
    "        self.text_filenames, self.labels = text_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.text_filenames)/ (self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Here, you have to imprement what the data looks like in each epcho\n",
    "        filename_List =  self.text_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        #print(filename_List)\n",
    "        Text_batch_x = [] \n",
    "        for filename in filename_List:  \n",
    "            Text_x = np.array(LineCNN_Collection.find_one({\"Filename\":filename})['LineMatrix'])\n",
    "            Text_x = Text_x.reshape(_num_Lines,_num_LineLen, _num_WEDim,1) #(num_sentence, 20 word ,100dim WE, 1for cnn)\n",
    "            Text_batch_x.append(Text_x)\n",
    "            \n",
    "        y_List = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return np.array(Text_batch_x),np.array(y_List)\n",
    "    def getitem(self, idx):\n",
    "        #Here, you have to imprement what the data looks like in each epcho\n",
    "        \n",
    "        return self.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDG_train = LyricDataGenerator(x_train, y_train,_batchSize)\n",
    "LDG_test = LyricDataGenerator(x_test, y_test,_batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = LDG_train.getitem(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 80, 25, 100, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This AUC callback is for STL\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class AUC_callback(Callback):\n",
    "    def __init__(self,y,SDG,log_name):\n",
    "        self.y = y\n",
    "        self.SDG = SDG\n",
    "        self.log_name = log_name\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        Skip_Tag = []\n",
    "        \n",
    "        y_pred = self.model.predict_generator(self.SDG) # (#data x 50()) \n",
    "        #print(y_pred.shape,self.y.shape,len(self.SDG.text_filenames))\n",
    "        for i in range(len(y_pred)):\n",
    "            for j in range(len(y_pred[i])):\n",
    "                if y_pred[i][j] >= 0.5 : \n",
    "                    y_pred[i][j] = 1\n",
    "                else:\n",
    "                    y_pred[i][j] = 0\n",
    "        \n",
    "        #print(y_pred.shape,self.y.shape)\n",
    "        \n",
    "        \n",
    "        AUC_this_epoch = roc_auc_score(self.y ,y_pred)\n",
    "        logs[self.log_name] = AUC_this_epoch\n",
    "        print('%s : %s '% (self.log_name,(str(round(AUC_this_epoch,5)))))\n",
    "        \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_test_callback =AUC_callback(y_test,LDG_test,'AUC_test')\n",
    "AUC_train_callback =AUC_callback(y_train,LDG_train,'AUC_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.epoch_time_end = time.time()\n",
    "        self.times.append(self.epoch_time_end - self.epoch_time_start)\n",
    "        logs['Timer'] = self.epoch_time_end - self.epoch_time_start\n",
    "time_callback = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=_stopEpcho, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multitask_loss(y_true, y_pred):\n",
    "    # Avoid divide by 0\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # Multi-task loss\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples = len(x_train)\n",
    "num_validation_samples = len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1368/1369 [============================>.] - ETA: 0s - loss: 0.4069 - acc: 0.8473"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.utils import multi_gpu_model\n",
    "parallel_model = multi_gpu_model(Main_model, gpus=2)\n",
    "parallel_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "History = parallel_model.fit_generator(\n",
    "                    generator= LDG_train,\n",
    "                    steps_per_epoch=(num_training_samples // _batchSize),\n",
    "                    epochs= _epchos,\n",
    "                    verbose=1,\n",
    "                    validation_data= LDG_test,\n",
    "                    validation_steps=(num_validation_samples // _batchSize),\n",
    "                    workers=12, use_multiprocessing=True,\n",
    "                    callbacks = [early_stopping,time_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallLDG_train = LyricDataGenerator(x_train[:10], y_train[:10],_batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parallel_model.predict_generator(smallLDG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64109516, 0.28912848, 0.3879006 , 0.31265792, 0.08526577,\n",
       "       0.17852658, 0.27549997, 0.24905545, 0.08435257, 0.20332344,\n",
       "       0.21299836, 0.04055744, 0.22828299, 0.32872945, 0.11536492,\n",
       "       0.12245547, 0.12674901, 0.10242686, 0.21375282, 0.05019374,\n",
       "       0.17104422, 0.29658225, 0.05775585, 0.18073812, 0.11680882,\n",
       "       0.16215992, 0.14801858, 0.13594046, 0.2005305 , 0.00577888,\n",
       "       0.09297061, 0.12293613, 0.13715751, 0.06519513, 0.16766681,\n",
       "       0.08393165, 0.15374486, 0.03631251, 0.12070651, 0.09195225,\n",
       "       0.15188475, 0.09428295, 0.1248062 , 0.00782196, 0.05357476,\n",
       "       0.04428873, 0.10017511, 0.07161396, 0.04204907, 0.04719784],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63993925, 0.2862898 , 0.38756743, 0.31537664, 0.08484082,\n",
       "       0.17749329, 0.27299446, 0.24521416, 0.08285759, 0.2019541 ,\n",
       "       0.21280228, 0.04040561, 0.22881104, 0.32752085, 0.1154738 ,\n",
       "       0.12185775, 0.12630685, 0.10211127, 0.21303959, 0.04968839,\n",
       "       0.172335  , 0.2969863 , 0.05777103, 0.1811137 , 0.11492516,\n",
       "       0.16255146, 0.14633226, 0.13628688, 0.19908823, 0.00579213,\n",
       "       0.09253025, 0.12371977, 0.13751687, 0.06520582, 0.1664405 ,\n",
       "       0.08399924, 0.1513631 , 0.03639603, 0.12148111, 0.09216613,\n",
       "       0.15021965, 0.09303892, 0.12490935, 0.00764366, 0.05380074,\n",
       "       0.0440358 , 0.10068581, 0.07093697, 0.04154344, 0.04676229],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = parallel_model.predict_generator(smallLDG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4085789 , 0.20232825, 0.22121426, 0.2251865 , 0.08814202,\n",
       "       0.1351604 , 0.15566503, 0.12493239, 0.04917085, 0.12122378,\n",
       "       0.10211617, 0.03356805, 0.14342067, 0.12755032, 0.18857175,\n",
       "       0.06778888, 0.1100345 , 0.11518778, 0.10447442, 0.05100651,\n",
       "       0.13747   , 0.09994594, 0.03858612, 0.12264695, 0.08557823,\n",
       "       0.0793603 , 0.07214601, 0.08023074, 0.09906282, 0.01274512,\n",
       "       0.1036813 , 0.07072857, 0.1084598 , 0.07173244, 0.07459857,\n",
       "       0.05618154, 0.07240815, 0.03245007, 0.07520631, 0.06049702,\n",
       "       0.07141275, 0.05335618, 0.06614666, 0.01751685, 0.06898241,\n",
       "       0.03130869, 0.0832616 , 0.04428142, 0.03803425, 0.04306855],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44173026, 0.2374732 , 0.23722392, 0.22026414, 0.08128575,\n",
       "       0.15096708, 0.18695475, 0.14923702, 0.060594  , 0.12776606,\n",
       "       0.11899145, 0.03281648, 0.14720565, 0.14632595, 0.18456192,\n",
       "       0.06724853, 0.12377871, 0.13132325, 0.11808017, 0.06334044,\n",
       "       0.1342258 , 0.10744365, 0.03601804, 0.12794243, 0.10678806,\n",
       "       0.08363817, 0.08407989, 0.08699004, 0.11468057, 0.01077297,\n",
       "       0.10378685, 0.07477808, 0.11557111, 0.06754161, 0.08978192,\n",
       "       0.06166533, 0.08988193, 0.02571851, 0.08343556, 0.05272269,\n",
       "       0.08044222, 0.06407141, 0.07051423, 0.0188871 , 0.07783408,\n",
       "       0.03585695, 0.08384464, 0.05452531, 0.04334679, 0.05519047],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_string = parallel_model.to_json()\n",
    "with codecs.open('Lyric_STL.json','w', encoding = 'utf8') as outfile:\n",
    "    json.dump(json_string,outfile)\n",
    "#parallel_model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 3s 313ms/step - loss: 0.7100 - acc: 0.5280\n"
     ]
    }
   ],
   "source": [
    "History = Main_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 6/10 [=================>............] - ETA: 1:01 - loss: 0.5984 - acc: 0.8533"
     ]
    }
   ],
   "source": [
    "History = Main_model.fit_generator(\n",
    "                    generator= LDG_train,\n",
    "                    #steps_per_epoch=(num_training_samples // _batchsize),\n",
    "                    epochs= _epchos,\n",
    "                    verbose=1,\n",
    "                    validation_data= LDG_test,\n",
    "                    #validation_steps=(num_validation_samples // _batchsize),\n",
    "                    #workers=3, use_multiprocessing=True,\n",
    "                    callbacks = [AUC_train_callback, AUC_test_callback,early_stopping,time_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in x_test:\n",
    "    text = np.array(LineCNN_Collection.find_one({\"Filename\":filename})['LineMatrix'])\n",
    "    if text.shape != (80,25,100) : \n",
    "        print(filename,text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
